{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/btekgit/AdaptiveCNN/blob/master/Cas_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=\"1\"\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "sid = 9\n",
    "np.random.seed(sid)\n",
    "tf.random.set_random_seed(sid)\n",
    "tf.reset_default_graph()\n",
    "tf.random.set_random_seed(sid)\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.utils import conv_utils\n",
    "from keras import activations, regularizers, constraints\n",
    "from keras import initializers\n",
    "from keras.engine import InputSpec\n",
    "#import numpy as np\n",
    "#import tensorflow as tf\n",
    "#import tensorflow as tf\n",
    "\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def idx_init(shape, dtype='float32'):\n",
    "    idxs = np.zeros((shape[0], shape[1]),dtype)\n",
    "    c = 0\n",
    "    # assumes square filters\n",
    "    \n",
    "    wid = np.int(np.sqrt(shape[0]))\n",
    "    hei =np.int(np.sqrt(shape[0]))\n",
    "    f = np.float32\n",
    "    for x in np.arange(wid):  # / (self.incoming_width * 1.0):\n",
    "        for y in np.arange(hei):  # / (self.incoming_height * 1.0):\n",
    "            idxs[c, :] = np.array([x/f(wid-1), y/f(hei-1)],dtype)\n",
    "            c += 1\n",
    "\n",
    "    return idxs\n",
    "\n",
    "def cov_init(shape, dtype='float32'):\n",
    "    \n",
    "    cov = np.identity(shape[1], dtype)\n",
    "    # shape [0] must have self.incoming_channels * self.num_filters\n",
    "    cov = np.repeat(cov[np.newaxis], shape[0], axis=0)\n",
    "    \n",
    "    #for t in range(shape[0]):\n",
    "    #    cov[t] = cov[t]\n",
    "    return cov\n",
    "\n",
    "def sigma_init(shape, initsigma, dtype='float32'):\n",
    "        \n",
    "   if isinstance(initsigma,float):  #initialize it with the given scalar\n",
    "       sigma = initsigma*np.ones(shape[0],dtype='float32')\n",
    "   elif isinstance(initsigma,tuple) and len(initsigma)==2: #linspace in range\n",
    "       sigma = np.linspace(initsigma[0], initsigma[1], shape[0],dtype=dtype)\n",
    "   elif isinstance(initsigma,np.ndarray): # set the values directly from array\n",
    "       sigma = (initsigma).astype(dtype=dtype)\n",
    "   else:\n",
    "       print(\"Default initial sigma value 0.1 will be used\")\n",
    "       sigma = np.float32(0.1)*np.ones(shape[0],dtype=dtype)\n",
    "\n",
    "   print(\"Scale initializer:\",sigma)\n",
    "   return sigma.astype(dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DAdaptive(Layer):\n",
    "    def __init__(self, rank, nfilters,\n",
    "                 kernel_size,\n",
    "                 strides=1,\n",
    "                 padding='valid',\n",
    "                 output_padding=None,\n",
    "                 data_format=None,\n",
    "                 dilation_rate=1,\n",
    "                 activation=None,\n",
    "                 use_bias=False,\n",
    "                 kernel_regularizer=None,\n",
    "                 gain=1.0,\n",
    "                 init_sigma=0.1,\n",
    "                 init_w=initializers.glorot_uniform(),\n",
    "                 init_bias = initializers.Constant(),\n",
    "                 trainsigmas=True,\n",
    "                 trainWeights=True,\n",
    "                 reg_bias=None,\n",
    "                 **kwargs):\n",
    "        super(Conv2DAdaptive, self).__init__(**kwargs)\n",
    "        #def __init__(self, num_filters, kernel_sigmaze, incoming_channels=1, **kwargs):\n",
    "        self.rank = rank\n",
    "        self.nfilters = nfilters\n",
    "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        self.data_format = data_format\n",
    "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
    "        self.gain = gain     \n",
    "        self.initsigma=init_sigma\n",
    "        self.initW =init_w\n",
    "        self.trainsigmas = trainsigmas\n",
    "        self.trainWeights = trainWeights\n",
    "        self.bias_initializer =init_bias\n",
    "        self.bias_regularizer = reg_bias\n",
    "        self.bias_constraint = None\n",
    "        self.sigma =None\n",
    "                 \n",
    "        #self.input_shape = input_shape\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'))\n",
    "        print(kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.num_filters = nfilters\n",
    "        #self.incoming_channels = incoming_channels\n",
    "        \n",
    "        \n",
    "        self.output_padding = output_padding\n",
    "        if self.output_padding is not None:\n",
    "            self.output_padding = conv_utils.normalize_tuple(\n",
    "                self.output_padding, 2, 'output_padding')\n",
    "            for stride, out_pad in zip(self.strides, self.output_padding):\n",
    "                if out_pad >= stride:\n",
    "                    raise ValueError('Stride ' + str(self.strides) + ' must be '\n",
    "                                     'greater than output padding ' +str(self.output_padding))\n",
    "                    \n",
    "        super(Conv2DAdaptive, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        \n",
    "        self.input_channels = input_dim\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.nfilters)\n",
    "        print(\"kernel shape:\",kernel_shape)\n",
    "\n",
    "        self.bias = None\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        \n",
    "        kernel_size = self.kernel_size\n",
    "        # Idxs Init\n",
    "        #mu = np.array([kernel_size[0] // 2, kernel_size[1] // 2])\n",
    "        mu = np.array([0.5, 0.5])\n",
    "\n",
    "\n",
    "        # Convert Types\n",
    "        self.mu = mu.astype(dtype='float32')\n",
    "\n",
    "        # Shared Parameters\n",
    "        # below works for only two dimensional cov \n",
    "        #self.cov = self.add_weight(shape=[input_dim*self.filters,2,2], \n",
    "        #                          name=\"cov\", initializer=cov_init, trainable=False)\n",
    "        \n",
    "        #from functools import partial\n",
    "\n",
    "        #sigma_initializer = partial(sigma_init,initsigma=self.initsigma)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "        self.idxs= idx_init(shape=[kernel_size[0]*kernel_size[1],2])\n",
    "        \n",
    "        self.Sigma = self.add_weight(shape=(self.nfilters,),\n",
    "                                          name='Sigma',\n",
    "                                          initializer=initializers.Constant(self.initsigma),\n",
    "                                          trainable=self.trainsigmas,\n",
    "                                          constraint= constraints.NonNeg())\n",
    "        \n",
    "        self.W = self.add_weight(shape=[kernel_size[0],kernel_size[1],\n",
    "                                        self.input_channels,self.nfilters],\n",
    "                                 name='Weights',\n",
    "                                 initializer=self.weight_init,\n",
    "                                 trainable=True,#self.trainWeights,\n",
    "                                 constraint=None)\n",
    "        \n",
    "       \n",
    "#        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "#                                      initializer=initializers.,\n",
    "#                                      name='kernel',trainable=False,\n",
    "#                                      regularizer=None,\n",
    "#                                      constraint=None)\n",
    "        \n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.nfilters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        \n",
    "        super(Conv2DAdaptive, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "        \n",
    "\n",
    "    \n",
    "    def U(self):\n",
    "  \n",
    "        #e1 = (self.idxs - self.mu)\n",
    "        #print(\"e1.shape\",e1.shape)\n",
    "        #print(\"cov scaler shape\",self.cov_scaler)\n",
    "   \n",
    "        #print(self.cov.shape)\n",
    "        #print(len(tf.unstack(self.cov,axis=0)))\n",
    "        #print( tf.linalg.inv(tf.unstack(self.cov,axis=0)[0]))\n",
    "        # tensorflow does not need scan it does the same op to all covs.\n",
    "        #cov_inv = self.cov\n",
    "        #cov_scaled =self.cov_scaler*self.cov\n",
    "#        cov_scaled = tf.scalar_mul(self.cov_scaler,self.cov)\n",
    "#        print(self.cov.shape, self.cov_scaler.shape )\n",
    "#        cov_scaled = K.batch_dot(self.cov_scaler,self.cov, axes=[1,2])\n",
    "        #cov_inv = tf.linalg.inv(cov_scaled)\n",
    "        #print(\"cov_scaled :\",cov_scaled.shape)\n",
    "        #cov_inv = K.map_fn(lambda x: tf.linalg.inv(x), elems=tf.unstack(self.cov,axis=0))\n",
    "       \n",
    "\n",
    "        #e2 = K.dot(e1, K.transpose(cov_inv))\n",
    "        #ex = K.batch_dot(e2, e1, axes=[[1], [1]])\n",
    "        #result = K.exp(-(1 / 2.0) * ex)\n",
    "\n",
    "        up= K.sum((self.idxs - self.mu)**2, axis=1)\n",
    "        #print(\"up.shape\",up.shape)\n",
    "        up = K.expand_dims(up,axis=1,)\n",
    "        #print(\"up.shape\",up.shape)\n",
    "        # clipping scaler in range to prevent div by 0 or negative cov. \n",
    "        sigma = K.clip(self.Sigma,0.01,5.0)\n",
    "        #cov_scaler = self.cov_scaler\n",
    "        dwn = 2 * ( sigma ** 2)\n",
    "        #scaler = (np.pi*self.cov_scaler**2) * (self.idxs.shape[0])\n",
    "        result = K.exp(-up / dwn)\n",
    "        \n",
    "\n",
    "\n",
    "        # Transpose is super important.\n",
    "        #filter: A 4-D `Tensor` with the same type as `value` and shape\n",
    "        #`[height, width, in_channels,output_channels]`\n",
    "        # we do not care about input channels\n",
    "\n",
    "        masks = K.reshape(result,(self.kernel_size[0], \n",
    "                                  self.kernel_size[1],\n",
    "                                  1,self.nfilters))   \n",
    "\n",
    "         \n",
    "        #sum normalization each filter has sum 1\n",
    "        #sums = K.sum(masks**2, axis=(0, 1), keepdims=True)\n",
    "        #print(sums)\n",
    "        #gain = K.constant(self.gain, dtype='float32')\n",
    "        \n",
    "        #Normalize\n",
    "        masks /= K.sqrt(K.sum(K.square(masks), axis=(0, 1),keepdims=True))\n",
    "        # make norm sqrt(filterw x filterh x self.incoming_channel)\n",
    "        # the reason for this is if you take U all ones(self.kernel_size[0],kernel_size[1], num_channels)\n",
    "        # its norm will sqrt(wxhxc)\n",
    "        print(\"Vars: \",self.input_channels,self.kernel_size[0],self.kernel_size[1])\n",
    "        masks *= K.sqrt(K.constant(self.input_channels*self.kernel_size[0]*self.kernel_size[1]))\n",
    "        \n",
    "        #masks *= (gain*np.sqrt(self.kernel_size[0]*self.kernel_size[1]))\n",
    "        #ums = sums * sums\n",
    "        #print(\"sums shape: \", sums.shape)\n",
    "        \n",
    "        # Sum normalisation\n",
    "        \n",
    "        #masks = masks * (gain/K.sqrt(sums))\n",
    "        #masks = masks * (gain/sums)\n",
    "        #print(\"masks shape\", masks.shape)\n",
    "        #print(\"masks mask\", K.mean(masks))\n",
    "        return masks\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        if self.data_format == 'channels_first':\n",
    "          h_axis, w_axis = 2, 3\n",
    "          c_axis= 1\n",
    "          \n",
    "        else:\n",
    "            h_axis, w_axis = 1, 2\n",
    "            c_axis=3\n",
    "            \n",
    "        ##BTEK \n",
    "        in_channels =input_shape[c_axis]\n",
    "        \n",
    "\n",
    "\n",
    "        ##BTEK \n",
    "        print(\"Calling self.U:\")\n",
    "        kernel = self.U()\n",
    "        print(\"kernel shape in output:\",kernel.shape)\n",
    "        if self.input_channels>1:\n",
    "            kernel = K.repeat_elements(kernel, self.input_channels, axis=2)\n",
    "            print(\"kernel reshaped :\",kernel.shape)\n",
    "        print(\"inputs shape\",inputs.shape)\n",
    "        #print(K.eval(kernel))\n",
    "        # multiply with weights\n",
    "        kernel = kernel*self.W\n",
    "        \n",
    "        #---------------------------------------------------------------------\n",
    "        print(\"Trainable weights\", self._trainable_weights)\n",
    "        outputs = K.conv2d(\n",
    "                inputs,\n",
    "                kernel,\n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "        \n",
    "        print(outputs.shape)\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[1:-1]\n",
    "        elif self.data_format == 'channels_first':\n",
    "            space = input_shape[2:]\n",
    "        new_space = []\n",
    "        for i in range(len(space)):\n",
    "            new_dim = conv_utils.conv_output_length(\n",
    "                space[i],\n",
    "                self.kernel_size[i],\n",
    "                padding=self.padding,\n",
    "                stride=self.strides[i],\n",
    "                dilation=self.dilation_rate[i])\n",
    "            new_space.append(new_dim)\n",
    "        if self.data_format == 'channels_last':\n",
    "            return (input_shape[0],) + tuple(new_space) + (self.nfilters,)\n",
    "        elif self.data_format == 'channels_first':\n",
    "            return (input_shape[0], self.filters) + tuple(new_space)\n",
    "        #return tuple(output_shape)\n",
    "        \n",
    "    def weight_init(self,shape):\n",
    "        #only implements channel last and HE uniform\n",
    "        initer = 'He'\n",
    "        distribution = 'uniform'\n",
    "        kernel = K.eval(self.U())\n",
    "        print(\"Kernel max, mean, min: \", np.max(kernel), np.mean(kernel), np.min(kernel))\n",
    "        W = np.zeros(shape=shape, dtype='float32')\n",
    "        print(\"kernel shape:\", kernel.shape, \", W shape: \",W.shape)\n",
    "        # for Each Gaussian initialize a new set of weights\n",
    "        verbose=True\n",
    "        fan_out = np.prod(self.nfilters)*self.kernel_size[0]*self.kernel_size[1]\n",
    "        \n",
    "        for c in range(W.shape[-1]):\n",
    "            fan_in = np.sum((kernel[:,:,:,c])**2)\n",
    "            fan_in *= self.input_channels\n",
    "            if initer == 'He':\n",
    "                std = self.gain * np.sqrt(2.0) / np.sqrt(fan_in)\n",
    "            else:\n",
    "                std = self.gain * np.sqrt(2.0) / np.sqrt(fan_in+fan_out)\n",
    "            \n",
    "            if c == 0:\n",
    "                print(\"Std here:\",std)\n",
    "            if distribution == 'uniform':\n",
    "                std *= np.sqrt(3.0) \n",
    "                w_vec = np.random.uniform(low=-std, high=std, size=W.shape[:-1])\n",
    "            else:\n",
    "                std = std/ .87962566103423978\n",
    "                w_vec = np.random.normal(scale=std, size=W.shape[:-1])\n",
    "            W[:,:,:,c] = w_vec.astype('float32')\n",
    "            \n",
    "        return W\n",
    "\n",
    "#test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    #import tensorflow as tf\n",
    "    #from gausslayer import GaussScaler\n",
    "    #import numpy as np\n",
    "\n",
    "    from keras.losses import mse\n",
    "    import keras\n",
    "    from keras.datasets import mnist,fashion_mnist, cifar10\n",
    "    from keras.models import Sequential, Model\n",
    "    from keras.layers import Input, Dense, Dropout, Flatten, Conv2D\n",
    "    from skimage import filters\n",
    "    from keras import backend as K\n",
    "    \n",
    "    K.clear_session()\n",
    "    \n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    inputimg = x_train[0]/255\n",
    "    sh = (inputimg.shape[0],inputimg.shape[1],1)\n",
    "    outputimages = np.zeros(shape=[inputimg.shape[0],inputimg.shape[1],3],dtype='float32')\n",
    "    outputimages[:,:,0] = filters.gaussian(inputimg,sigma=1)\n",
    "    outputimages[:,:,1] = filters.sobel_h(inputimg)\n",
    "    outputimages[:,:,2] = filters.sobel_v(filters.gaussian(inputimg,sigma=0.5))\n",
    "    \n",
    "    y = y_train[0]\n",
    "    \n",
    "    node_in = Input(shape=sh, name='inputlayer')\n",
    "    # smaller initsigma does not work well. \n",
    "    node_acnn = Conv2DAdaptive(rank=2,nfilters=3,kernel_size=(7,7), \n",
    "                             data_format='channels_last',\n",
    "                             padding='same',name='acnn',activation='linear',\n",
    "                             init_sigma=0.25, trainsigmas=True, \n",
    "                             trainWeights=True)(node_in)\n",
    "    \n",
    "    #node_acnn = Conv2D(filters=3,kernel_size=(7,7), \n",
    "    #                         data_format='channels_last',\n",
    "    #                         padding='same',name='acnn',activation='linear')(node_in)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=node_in, outputs=[node_acnn])\n",
    "        \n",
    "   # model.summary()\n",
    "\n",
    "    from lr_multiplier import LearningRateMultiplier\n",
    "    from keras.optimizers import SGD\n",
    "    multipliers = {'acnn/Sigma:0': 0.1, 'acnn/Weights:0':1.0}\n",
    "    opt = LearningRateMultiplier(SGD, lr_multipliers=multipliers, \n",
    "                             lr=0.1, momentum=0.9,decay=0, nesterov=False)#sgd = keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0000) \n",
    "    #opt = SGD(lr=0.01)\n",
    "    model.compile(loss=mse, optimizer=opt, metrics=None)\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    inputimg2 = np.expand_dims(np.expand_dims(inputimg,axis=0), axis=3)\n",
    "    outputimages2 = np.expand_dims(outputimages,axis=0)\n",
    "    \n",
    "    #print info about weights\n",
    "    acnn_layer = model.get_layer('acnn')    \n",
    "    all_params=acnn_layer.weights\n",
    "    print(\"All params:\",all_params)\n",
    "    acnn_params = acnn_layer.get_weights()\n",
    "    for i,v in enumerate(all_params):\n",
    "        print(v, \", max, mean\", np.max(acnn_params[i]),np.mean(acnn_params[i]),\"\\n\")\n",
    "        \n",
    "        \n",
    "    history = model.fit(inputimg2, outputimages2,\n",
    "              batch_size=1,\n",
    "              epochs=500,\n",
    "              verbose=0)\n",
    "    \n",
    "    #print info about weights\n",
    "    print(\"After training:\",all_params)\n",
    "    acnn_params = acnn_layer.get_weights()\n",
    "    for i,v in enumerate(all_params):\n",
    "        print(v, \", max, mean\", np.max(acnn_params[i]),np.mean(acnn_params[i]),\"\\n\")\n",
    "    \n",
    " \n",
    "    #out = acnn_layer.get_output_at(0)\n",
    "#\n",
    "#    with tf.Session() as sess:\n",
    "#        sess.run(tf.global_variables_initializer())\n",
    "#        outval = sess.run(out, feed_dict={inputs:inputimg2})\n",
    "#        acnn_layer_var = acnn_layer.get_weights()\n",
    "    \n",
    "    \n",
    "    pred_images = model.predict(inputimg2,  verbose=1)\n",
    "    print(\"Prediction shape\",pred_images.shape)\n",
    "    plt = True\n",
    "    if plt:\n",
    "        print(\"Plotting kernels before...\")\n",
    "        import matplotlib.pyplot as plt\n",
    "        num_images=min(pred_images.shape[3],12)\n",
    "        fig=plt.figure(figsize=(10,5))\n",
    "        plt.subplot(3, num_images, 2)\n",
    "        plt.imshow(np.squeeze(inputimg2[0,:,:,0]))\n",
    "        for i in range(num_images):\n",
    "            plt.subplot(3, num_images, i+4)\n",
    "            plt.imshow(np.squeeze(outputimages2[0,:,:,i]))\n",
    "            print(\"Max-in:\",i,\" \",np.max(np.squeeze(outputimages2[0,:,:,i])))\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            plt.subplot(3, num_images, i+7)\n",
    "            plt.imshow(np.squeeze(pred_images[0,:,:,i]))\n",
    "            print(\"MAx:\",\"pred\",i,np.max(np.squeeze(pred_images[0,:,:,i])))\n",
    "        #fig.colorbar(im, ax=ax1)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    #print( model.get_layer('acnn').output )\n",
    "    print( \"Final Sigmas\", model.get_layer('acnn').get_weights()[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sid = 9\n",
    "tf.reset_default_graph()\n",
    "np.random.seed(sid)\n",
    "tf.random.set_random_seed(sid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "WARNING:tensorflow:From /home/btek/anaconda2/envs/kerasgpu/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/btek/anaconda2/envs/kerasgpu/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "{'name': 'acnn-1'}\n",
      "kernel shape: (5, 5, 32, 32)\n",
      "Vars:  32 5 5\n",
      "Kernel max, mean, min:  19.875338 3.1913235 0.038368445\n",
      "kernel shape: (5, 5, 1, 32) , W shape:  (5, 5, 32, 32)\n",
      "Std here: 0.008838835439181498\n",
      "Calling self.U:\n",
      "Vars:  32 5 5\n",
      "kernel shape in output: (5, 5, 1, 32)\n",
      "kernel reshaped : (5, 5, 32, 32)\n",
      "inputs shape (?, 28, 28, 32)\n",
      "Trainable weights [<tf.Variable 'acnn-1/Sigma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'acnn-1/Weights:0' shape=(5, 5, 32, 32) dtype=float32_ref>]\n",
      "(?, 28, 28, 32)\n",
      "{'name': 'acnn-2'}\n",
      "kernel shape: (5, 5, 32, 32)\n",
      "Vars:  32 5 5\n",
      "Kernel max, mean, min:  19.875338 3.1913235 0.038368445\n",
      "kernel shape: (5, 5, 1, 32) , W shape:  (5, 5, 32, 32)\n",
      "Std here: 0.008838835439181498\n",
      "Calling self.U:\n",
      "Vars:  32 5 5\n",
      "kernel shape in output: (5, 5, 1, 32)\n",
      "kernel reshaped : (5, 5, 32, 32)\n",
      "inputs shape (?, 14, 14, 32)\n",
      "Trainable weights [<tf.Variable 'acnn-2/Sigma:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'acnn-2/Weights:0' shape=(5, 5, 32, 32) dtype=float32_ref>]\n",
      "(?, 14, 14, 32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "acnn-1 (Conv2DAdaptive)      (None, 28, 28, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "acnn-2 (Conv2DAdaptive)      (None, 14, 14, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 263,466\n",
      "Trainable params: 263,210\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "<lr_multiplier.LearningRateMultiplier object at 0x7f24d6360fd0>\n",
      "Plotting kernels before...\n",
      "Sigmas before [0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2\n",
      " 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2 0.2]\n",
      "Vars:  32 5 5\n",
      "U shape (5, 5, 1, 32)\n",
      "U max: 19.875338\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/btek/anaconda2/envs/kerasgpu/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 30s 503us/step - loss: 0.3274 - acc: 0.8978 - val_loss: 0.0745 - val_acc: 0.9785\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.1012 - acc: 0.9697 - val_loss: 0.0472 - val_acc: 0.9856\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.0777 - acc: 0.9769 - val_loss: 0.0414 - val_acc: 0.9867\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0637 - acc: 0.9813 - val_loss: 0.0368 - val_acc: 0.9877\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0556 - acc: 0.9825 - val_loss: 0.0320 - val_acc: 0.9885\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0495 - acc: 0.9846 - val_loss: 0.0299 - val_acc: 0.9896\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0462 - acc: 0.9859 - val_loss: 0.0306 - val_acc: 0.9902\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0421 - acc: 0.9871 - val_loss: 0.0297 - val_acc: 0.9907\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0392 - acc: 0.9878 - val_loss: 0.0267 - val_acc: 0.9912\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0366 - acc: 0.9885 - val_loss: 0.0263 - val_acc: 0.9918\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0352 - acc: 0.9890 - val_loss: 0.0225 - val_acc: 0.9928\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0323 - acc: 0.9902 - val_loss: 0.0226 - val_acc: 0.9918\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0307 - acc: 0.9906 - val_loss: 0.0227 - val_acc: 0.9929\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0302 - acc: 0.9904 - val_loss: 0.0238 - val_acc: 0.9922\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0275 - acc: 0.9915 - val_loss: 0.0190 - val_acc: 0.9943\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0276 - acc: 0.9912 - val_loss: 0.0209 - val_acc: 0.9932\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0213 - val_acc: 0.9934\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0243 - acc: 0.9926 - val_loss: 0.0179 - val_acc: 0.9944\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0232 - acc: 0.9926 - val_loss: 0.0211 - val_acc: 0.9927\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0243 - acc: 0.9922 - val_loss: 0.0175 - val_acc: 0.9946\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0223 - acc: 0.9933 - val_loss: 0.0215 - val_acc: 0.9934\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0223 - acc: 0.9932 - val_loss: 0.0192 - val_acc: 0.9941\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0206 - acc: 0.9935 - val_loss: 0.0165 - val_acc: 0.9943\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0201 - acc: 0.9935 - val_loss: 0.0166 - val_acc: 0.9946\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0168 - val_acc: 0.9948\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0192 - acc: 0.9939 - val_loss: 0.0174 - val_acc: 0.9943\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0179 - acc: 0.9942 - val_loss: 0.0168 - val_acc: 0.9949\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0169 - acc: 0.9947 - val_loss: 0.0153 - val_acc: 0.9952\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0164 - acc: 0.9951 - val_loss: 0.0171 - val_acc: 0.9944\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0162 - acc: 0.9952 - val_loss: 0.0180 - val_acc: 0.9946\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0163 - acc: 0.9948 - val_loss: 0.0169 - val_acc: 0.9948\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0159 - acc: 0.9948 - val_loss: 0.0185 - val_acc: 0.9943\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0154 - acc: 0.9951 - val_loss: 0.0169 - val_acc: 0.9949\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0141 - acc: 0.9955 - val_loss: 0.0160 - val_acc: 0.9954\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0147 - acc: 0.9953 - val_loss: 0.0203 - val_acc: 0.9940\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0135 - acc: 0.9958 - val_loss: 0.0168 - val_acc: 0.9943\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0132 - acc: 0.9957 - val_loss: 0.0179 - val_acc: 0.9945\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0128 - acc: 0.9959 - val_loss: 0.0160 - val_acc: 0.9947\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0135 - acc: 0.9957 - val_loss: 0.0177 - val_acc: 0.9947\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0123 - acc: 0.9961 - val_loss: 0.0160 - val_acc: 0.9951\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.0173 - val_acc: 0.9946\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.0174 - val_acc: 0.9944\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0108 - acc: 0.9967 - val_loss: 0.0198 - val_acc: 0.9936\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0115 - acc: 0.9963 - val_loss: 0.0160 - val_acc: 0.9954\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0110 - acc: 0.9966 - val_loss: 0.0164 - val_acc: 0.9951\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0108 - acc: 0.9964 - val_loss: 0.0163 - val_acc: 0.9953\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0110 - acc: 0.9964 - val_loss: 0.0165 - val_acc: 0.9949\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0161 - val_acc: 0.9950\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0154 - val_acc: 0.9956\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0105 - acc: 0.9967 - val_loss: 0.0160 - val_acc: 0.9947\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0096 - acc: 0.9969 - val_loss: 0.0162 - val_acc: 0.9943\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0085 - acc: 0.9974 - val_loss: 0.0152 - val_acc: 0.9953\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0092 - acc: 0.9972 - val_loss: 0.0173 - val_acc: 0.9950\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0091 - acc: 0.9970 - val_loss: 0.0172 - val_acc: 0.9949\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.0168 - val_acc: 0.9947\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0089 - acc: 0.9970 - val_loss: 0.0160 - val_acc: 0.9944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0092 - acc: 0.9971 - val_loss: 0.0168 - val_acc: 0.9951\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0188 - val_acc: 0.9942\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.0157 - val_acc: 0.9953\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0185 - val_acc: 0.9952\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0173 - val_acc: 0.9952\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0075 - acc: 0.9978 - val_loss: 0.0177 - val_acc: 0.9945\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0165 - val_acc: 0.9954\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0074 - acc: 0.9979 - val_loss: 0.0171 - val_acc: 0.9949\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0158 - val_acc: 0.9957\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0154 - val_acc: 0.9956\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0178 - val_acc: 0.9951\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0177 - val_acc: 0.9942\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0174 - val_acc: 0.9949\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0071 - acc: 0.9978 - val_loss: 0.0152 - val_acc: 0.9959\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0158 - val_acc: 0.9950\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0069 - acc: 0.9977 - val_loss: 0.0161 - val_acc: 0.9956\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0168 - val_acc: 0.9950\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0161 - val_acc: 0.9953\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0157 - val_acc: 0.9954\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0174 - val_acc: 0.9946\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0058 - acc: 0.9982 - val_loss: 0.0172 - val_acc: 0.9950\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0183 - val_acc: 0.9945\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0154 - val_acc: 0.9953\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0167 - val_acc: 0.9953\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0060 - acc: 0.9980 - val_loss: 0.0175 - val_acc: 0.9949\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0154 - val_acc: 0.9954\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0173 - val_acc: 0.9944\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0169 - val_acc: 0.9950\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0163 - val_acc: 0.9948\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0184 - val_acc: 0.9940\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0162 - val_acc: 0.9952\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0171 - val_acc: 0.9946\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 27s 442us/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0169 - val_acc: 0.9953\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0165 - val_acc: 0.9949\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0162 - val_acc: 0.9950\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0171 - val_acc: 0.9947\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 26s 438us/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0186 - val_acc: 0.9945\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0186 - val_acc: 0.9950\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0174 - val_acc: 0.9951\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0175 - val_acc: 0.9945\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0049 - acc: 0.9985 - val_loss: 0.0165 - val_acc: 0.9951\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0168 - val_acc: 0.9947\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0173 - val_acc: 0.9945\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 26s 440us/step - loss: 0.0041 - acc: 0.9988 - val_loss: 0.0182 - val_acc: 0.9946\n",
      "Test loss: 0.018170346284426115\n",
      "Test accuracy: 0.9946\n",
      "Plotting kernels after ...\n",
      "U max: 19.875338\n",
      "Sigmas after [0.45980087 0.3511471  0.3375127  0.20108819 0.28737518 0.3552522\n",
      " 0.45438352 0.4612872  0.28764728 0.5040724  0.33578533 0.45332932\n",
      " 0.50811094 0.47340786 0.44786435 0.3297086  0.3796951  0.30925333\n",
      " 0.06447897 0.1332532  0.26687542 0.370499   0.3821036  0.26412353\n",
      " 0.4572167  0.29835337 0.38854364 0.38995552 0.45372692 0.39455968\n",
      " 0.28563163 0.34701553]\n",
      "U shape (5, 5, 1, 32)\n",
      "kernel mean,var,max,min 5.358407 3.287479 9.120553 2.7955596\n",
      "kernel mean,var,max,min 4.9255543 7.738907 11.460048 1.5088717\n",
      "kernel mean,var,max,min 4.833947 8.6329565 11.892876 1.3248739\n",
      "kernel mean,var,max,min 3.2090344 21.702085 19.772524 0.04083378\n",
      "kernel mean,var,max,min 4.3898363 12.729348 13.897322 0.67333895\n",
      "kernel mean,var,max,min 4.9510083 7.4875154 11.33753 1.5639281\n",
      "kernel mean,var,max,min 5.345579 3.4247904 9.202631 2.7418334\n",
      "kernel mean,var,max,min 5.361817 3.2509184 9.098504 2.8101\n",
      "kernel mean,var,max,min 4.392743 12.703806 13.884357 0.67657256\n",
      "kernel mean,var,max,min 5.4428043 2.3758678 8.54103 3.1930428\n",
      "kernel mean,var,max,min 4.821529 8.752852 11.950701 1.3015168\n",
      "kernel mean,var,max,min 5.3430066 3.4522674 9.218921 2.731244\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs  ...\n",
      "Outputs shape (1, 28, 28, 32)\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "input mean,var,max 0.06930272 0.054472942 0.99607843\n",
      "ouput mean,var,max -6.9381266 11.377422 4.2927074 -19.90511\n",
      "ouput mean,var,max -5.3291607 7.260445 3.2959125 -16.158394\n",
      "ouput mean,var,max -5.4672713 7.564472 6.5262823 -15.440985\n",
      "ouput mean,var,max 6.3486567 21.567472 25.648273 -11.181173\n",
      "ouput mean,var,max -6.4494195 9.964275 -1.0239714 -19.290848\n",
      "ouput mean,var,max -5.465774 7.857143 8.9349 -15.8838825\n",
      "ouput mean,var,max -11.539818 5.929302 -3.0854282 -27.069918\n",
      "ouput mean,var,max -10.777902 11.1130085 -2.71864 -23.52884\n",
      "ouput mean,var,max -4.1632714 3.5333974 -0.9911916 -11.809115\n",
      "ouput mean,var,max -14.331493 23.959808 -4.3825936 -38.58509\n",
      "ouput mean,var,max -4.7784424 8.110535 8.502587 -16.624573\n",
      "ouput mean,var,max -8.592823 13.590618 7.922947 -18.486242\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist,cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization,Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "#dset='cifar10'#mnist\n",
    "dset='mnist'\n",
    "batch_size = 200\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "test_acnn=True\n",
    "\n",
    "if dset=='mnist':\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 28, 28  \n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    n_channels=1\n",
    "\n",
    "elif dset=='cifar10':    \n",
    "    img_rows, img_cols = 32,32\n",
    "    n_channels=3\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], n_channels, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], n_channels, img_rows, img_cols)\n",
    "    input_shape = (n_channels, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, n_channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, n_channels)\n",
    "    input_shape = (img_rows, img_cols, n_channels)\n",
    "        \n",
    "\n",
    "    \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                   activation='linear',padding='same',\n",
    "          input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='linear',padding='same'))\n",
    "#odel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#odel.add(Dense(128, activation='relu'))\n",
    "\n",
    "#odel.add(Dropout(0.25))\n",
    "\n",
    "  #=============================================================================\n",
    "if test_acnn:\n",
    "    model.add(Conv2DAdaptive(rank=2,nfilters=32,kernel_size=(5,5), \n",
    "                            data_format='channels_last',strides=1,\n",
    "                            padding='same',name='acnn-1', activation='linear',\n",
    "                            trainsigmas=True, trainWeights=True, init_sigma=0.2))\n",
    "else:\n",
    "    model.add(Conv2D(32, (3, 3), activation='linear',padding='same'))\n",
    "    \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "if test_acnn:\n",
    "    model.add(Conv2DAdaptive(rank=2,nfilters=32,kernel_size=(5,5), \n",
    "                            data_format='channels_last',strides=1,\n",
    "                            padding='same',name='acnn-2', activation='linear',\n",
    "                            init_sigma=0.2))\n",
    "else:\n",
    "    model.add(Conv2D(32, (3, 3), activation='linear',padding='same'))\n",
    "  \n",
    "      \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "  \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "   \n",
    "#=============================================================================\n",
    "    \n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "from lr_multiplier import LearningRateMultiplier\n",
    "\n",
    "multipliers = {'acnn-1/Sigma:0': 1.0,'acnn-1/Weights:0': 2.0,'acnn-2/Sigma:0': 1.0,'acnn-2/Weights:0': 2.0}\n",
    "opt = LearningRateMultiplier(SGD, lr_multipliers=multipliers, \n",
    "                             lr=0.05, momentum=0.1,decay=1e-8)\n",
    "print(opt)\n",
    "#opt = SGD(lr=0.01,momentum=0.5)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "plt = True\n",
    "if plt and test_acnn:\n",
    "    print(\"Plotting kernels before...\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    acnn_layer = model.get_layer('acnn-1')\n",
    "    ws = acnn_layer.get_weights()\n",
    "    print(\"Sigmas before\",ws[0])\n",
    "    u_func = K.function(inputs=[model.input], outputs=[acnn_layer.U()])\n",
    "    output_func = K.function(inputs=[model.input], outputs=[acnn_layer.output])\n",
    "\n",
    "    U_val=u_func([np.expand_dims(x_test[0], axis=0)])\n",
    "    \n",
    "    print(\"U shape\", U_val[0].shape)\n",
    "    print(\"U max:\", np.max(U_val[0][:,:,:,:]))\n",
    "    num_filt=min(U_val[0].shape[3],12)\n",
    "    fig=plt.figure(figsize=(10,5))\n",
    "    for i in range(num_filt):\n",
    "        ax1=plt.subplot(1, num_filt, i+1)\n",
    "        im = ax1.imshow(np.squeeze(U_val[0][:,:,0,i]))\n",
    "    fig.colorbar(im, ax=ax1)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "if plt and test_acnn:\n",
    "    print(\"Plotting kernels after ...\")\n",
    "    \n",
    "    print(\"U max:\", np.max(U_val[0][:,:,:,:]))\n",
    "    import matplotlib.pyplot as plt\n",
    "    ws = acnn_layer.get_weights()\n",
    "    print(\"Sigmas after\",ws[0])\n",
    "    U_val=u_func([np.expand_dims(x_test[2], axis=0)])\n",
    "    \n",
    "    print(\"U shape\", U_val[0].shape)\n",
    "    num_filt=min(U_val[0].shape[3],12)\n",
    "    fig=plt.figure(figsize=(16,5))\n",
    "    for i in range(num_filt):\n",
    "        ax=plt.subplot(1, num_filt, i+1)\n",
    "        kernel_u = U_val[0][:,:,0,i]\n",
    "        im = ax.imshow(np.squeeze(kernel_u))\n",
    "        print(\"kernel mean,var,max,min\",np.mean(kernel_u),\n",
    "                                       np.var(kernel_u),\n",
    "                                       np.max(kernel_u), np.min(kernel_u))\n",
    "    #fig.colorbar(im, ax=ax1)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(\"outputs  ...\")\n",
    "    \n",
    "    n=5\n",
    "    \n",
    "    out_val=output_func([np.expand_dims(x_test[5], axis=0)])\n",
    "    print(\"Outputs shape\", out_val[0].shape)\n",
    "    num_filt=min(out_val[0].shape[3],12)\n",
    "    fig=plt.figure(figsize=(16,10))\n",
    "    ax=plt.subplot(1, num_filt+1, 1)\n",
    "    im = ax.imshow(np.squeeze(x_test[5]))\n",
    "    print(y_test[5])\n",
    "    print(\"input mean,var,max\",np.mean(x_test[n]),np.var(x_test[n]),np.max(x_test[n]))\n",
    "    for i in range(num_filt):\n",
    "        ax=plt.subplot(1, num_filt+1, i+2)\n",
    "        out_im = out_val[0][0,:,:,i]\n",
    "        im = ax.imshow(np.squeeze(out_im))\n",
    "        \n",
    "        print(\"ouput mean,var,max\",np.mean(out_im),\n",
    "                                       np.var(out_im),\n",
    "                                       np.max(out_im),np.min(out_im))\n",
    "        #plt.colorbar(im,ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Cas-keras",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
