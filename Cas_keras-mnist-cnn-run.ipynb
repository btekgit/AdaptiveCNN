{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/btekgit/AdaptiveCNN/blob/master/Cas_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2o1HajCaf20e",
    "outputId": "1a4e9b20-2857-4b45-cf68-4740f06994b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.utils import conv_utils\n",
    "from keras import activations, regularizers, constraints\n",
    "from keras import initializers\n",
    "from keras.engine import InputSpec\n",
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def idx_init(shape, dtype='float32'):\n",
    "    idxs = np.zeros((shape[0], shape[1]),dtype)\n",
    "    c = 0\n",
    "    # assumes square filters\n",
    "    \n",
    "    wid = np.int(np.sqrt(shape[0]))\n",
    "    hei =np.int(np.sqrt(shape[0]))\n",
    "    f = np.float32\n",
    "    for x in np.arange(wid):  # / (self.incoming_width * 1.0):\n",
    "        for y in np.arange(hei):  # / (self.incoming_height * 1.0):\n",
    "            idxs[c, :] = np.array([x/f(wid-1), y/f(hei-1)],dtype)\n",
    "            c += 1\n",
    "\n",
    "    return idxs\n",
    "\n",
    "def cov_init(shape, dtype='float32'):\n",
    "    \n",
    "    cov = np.identity(shape[1], dtype)\n",
    "    # shape [0] must have self.incoming_channels * self.num_filters\n",
    "    cov = np.repeat(cov[np.newaxis], shape[0], axis=0)\n",
    "    \n",
    "    #for t in range(shape[0]):\n",
    "    #    cov[t] = cov[t]\n",
    "    return cov\n",
    "\n",
    "def sigma_init(shape, initsigma, dtype='float32'):\n",
    "        \n",
    "   if isinstance(initsigma,float):  #initialize it with the given scalar\n",
    "       sigma = initsigma*np.ones(shape[0],dtype='float32')\n",
    "   elif isinstance(initsigma,tuple) and len(initsigma)==2: #linspace in range\n",
    "       sigma = np.linspace(initsigma[0], initsigma[1], shape[0],dtype=dtype)\n",
    "   elif isinstance(initsigma,np.ndarray): # set the values directly from array\n",
    "       sigma = (initsigma).astype(dtype=dtype)\n",
    "   else:\n",
    "       print(\"Default initial sigma value 0.1 will be used\")\n",
    "       sigma = np.float32(0.1)*np.ones(shape[0],dtype=dtype)\n",
    "\n",
    "   print(\"Scale initializer:\",sigma)\n",
    "   return sigma.astype(dtype)\n",
    "\n",
    "\n",
    "\n",
    "class Conv2DAdaptive(Layer):\n",
    "    def __init__(self, rank, nfilters,\n",
    "                 kernel_size,\n",
    "                 strides=1,\n",
    "                 padding='valid',\n",
    "                 output_padding=None,\n",
    "                 data_format=None,\n",
    "                 dilation_rate=1,\n",
    "                 activation=None,\n",
    "                 use_bias=False,\n",
    "                 kernel_regularizer=None,\n",
    "                 gain=1.0,\n",
    "                 init_sigma=0.1,\n",
    "                 init_w=initializers.glorot_uniform(),\n",
    "                 init_bias = initializers.Constant(),\n",
    "                 trainsigmas=True,\n",
    "                 trainWeights=True,\n",
    "                 reg_bias=None,\n",
    "                 **kwargs):\n",
    "        super(Conv2DAdaptive, self).__init__(**kwargs)\n",
    "        #def __init__(self, num_filters, kernel_sigmaze, incoming_channels=1, **kwargs):\n",
    "        self.rank = rank\n",
    "        self.nfilters = nfilters\n",
    "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\n",
    "        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\n",
    "        self.padding = conv_utils.normalize_padding(padding)\n",
    "        self.data_format = data_format\n",
    "        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\n",
    "        self.activation = activations.get(activation)\n",
    "        self.use_bias = use_bias\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2)\n",
    "        self.gain = gain     \n",
    "        self.initsigma=init_sigma\n",
    "        self.initW =init_w\n",
    "        self.trainsigmas = trainsigmas\n",
    "        self.trainWeights = trainWeights\n",
    "        self.bias_initializer =init_bias\n",
    "        self.bias_regularizer = reg_bias\n",
    "        self.bias_constraint = None\n",
    "        self.sigma =None\n",
    "                 \n",
    "        #self.input_shape = input_shape\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'))\n",
    "        print(kwargs)\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        self.num_filters = nfilters\n",
    "        #self.incoming_channels = incoming_channels\n",
    "        \n",
    "        \n",
    "        self.output_padding = output_padding\n",
    "        if self.output_padding is not None:\n",
    "            self.output_padding = conv_utils.normalize_tuple(\n",
    "                self.output_padding, 2, 'output_padding')\n",
    "            for stride, out_pad in zip(self.strides, self.output_padding):\n",
    "                if out_pad >= stride:\n",
    "                    raise ValueError('Stride ' + str(self.strides) + ' must be '\n",
    "                                     'greater than output padding ' +str(self.output_padding))\n",
    "                    \n",
    "        super(Conv2DAdaptive, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs '\n",
    "                             'should be defined. Found `None`.')\n",
    "        input_dim = input_shape[channel_axis]\n",
    "        \n",
    "        self.input_channels = input_dim\n",
    "        kernel_shape = self.kernel_size + (input_dim, self.nfilters)\n",
    "        print(\"kernel shape:\",kernel_shape)\n",
    "\n",
    "        self.bias = None\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=self.rank + 2,\n",
    "                                    axes={channel_axis: input_dim})\n",
    "        self.built = True\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        \n",
    "        kernel_size = self.kernel_size\n",
    "        # Idxs Init\n",
    "        #mu = np.array([kernel_size[0] // 2, kernel_size[1] // 2])\n",
    "        mu = np.array([0.5, 0.5])\n",
    "\n",
    "\n",
    "        # Convert Types\n",
    "        self.mu = mu.astype(dtype='float32')\n",
    "\n",
    "        # Shared Parameters\n",
    "        # below works for only two dimensional cov \n",
    "        #self.cov = self.add_weight(shape=[input_dim*self.filters,2,2], \n",
    "        #                          name=\"cov\", initializer=cov_init, trainable=False)\n",
    "        \n",
    "        #from functools import partial\n",
    "\n",
    "        #sigma_initializer = partial(sigma_init,initsigma=self.initsigma)\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "        self.idxs= idx_init(shape=[kernel_size[0]*kernel_size[1],2])\n",
    "        \n",
    "        self.W = self.add_weight(shape=[kernel_size[0],kernel_size[1],\n",
    "                                        self.input_channels,self.nfilters],\n",
    "                                 name='Weights',initializer=self.initW,\n",
    "                                 trainable=True,#self.trainWeights,\n",
    "                                 constraint=None)\n",
    "        \n",
    "        self.Sigma = self.add_weight(shape=(self.nfilters,),\n",
    "                                          name='Sigma',\n",
    "                                          initializer=initializers.Constant(self.initsigma),\n",
    "                                          trainable=self.trainsigmas,\n",
    "                                          constraint= constraints.NonNeg())        \n",
    "#        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "#                                      initializer=initializers.,\n",
    "#                                      name='kernel',trainable=False,\n",
    "#                                      regularizer=None,\n",
    "#                                      constraint=None)\n",
    "        \n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.nfilters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        \n",
    "        super(Conv2DAdaptive, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "        \n",
    "\n",
    "    \n",
    "    def U(self):\n",
    "  \n",
    "        #e1 = (self.idxs - self.mu)\n",
    "        #print(\"e1.shape\",e1.shape)\n",
    "        #print(\"cov scaler shape\",self.cov_scaler)\n",
    "   \n",
    "        #print(self.cov.shape)\n",
    "        #print(len(tf.unstack(self.cov,axis=0)))\n",
    "        #print( tf.linalg.inv(tf.unstack(self.cov,axis=0)[0]))\n",
    "        # tensorflow does not need scan it does the same op to all covs.\n",
    "        #cov_inv = self.cov\n",
    "        #cov_scaled =self.cov_scaler*self.cov\n",
    "#        cov_scaled = tf.scalar_mul(self.cov_scaler,self.cov)\n",
    "#        print(self.cov.shape, self.cov_scaler.shape )\n",
    "#        cov_scaled = K.batch_dot(self.cov_scaler,self.cov, axes=[1,2])\n",
    "        #cov_inv = tf.linalg.inv(cov_scaled)\n",
    "        #print(\"cov_scaled :\",cov_scaled.shape)\n",
    "        #cov_inv = K.map_fn(lambda x: tf.linalg.inv(x), elems=tf.unstack(self.cov,axis=0))\n",
    "       \n",
    "\n",
    "        #e2 = K.dot(e1, K.transpose(cov_inv))\n",
    "        #ex = K.batch_dot(e2, e1, axes=[[1], [1]])\n",
    "        #result = K.exp(-(1 / 2.0) * ex)\n",
    "\n",
    "        up= K.sum((self.idxs - self.mu)**2, axis=1)\n",
    "        #print(\"up.shape\",up.shape)\n",
    "        up = K.expand_dims(up,axis=1,)\n",
    "        #print(\"up.shape\",up.shape)\n",
    "        # clipping scaler in range to prevent div by 0 or negative cov. \n",
    "        sigma = K.clip(self.Sigma,0.01,5.0)\n",
    "        #cov_scaler = self.cov_scaler\n",
    "        dwn = 2 * ( sigma ** 2)\n",
    "        #scaler = (np.pi*self.cov_scaler**2) * (self.idxs.shape[0])\n",
    "        result = K.exp(-up / dwn)\n",
    "        \n",
    "\n",
    "\n",
    "        # Transpose is super important.\n",
    "        #filter: A 4-D `Tensor` with the same type as `value` and shape\n",
    "        #`[height, width, in_channels,output_channels]`\n",
    "        # we do not care about input channels\n",
    "\n",
    "        masks = K.reshape(result,(self.kernel_size[0], \n",
    "                                  self.kernel_size[1],\n",
    "                                  1,self.nfilters))   \n",
    "\n",
    "         \n",
    "        #sum normalization each filter has sum 1\n",
    "        #sums = K.sum(masks**2, axis=(0, 1), keepdims=True)\n",
    "        #print(sums)\n",
    "        #gain = K.constant(self.gain, dtype='float32')\n",
    "        \n",
    "        #Normalize\n",
    "        masks /= K.sqrt(K.sum(K.square(masks), axis=(0, 1),keepdims=True))\n",
    "        # make norm sqrt(filterw x filterh x self.incoming_channel)\n",
    "        # the reason for this is if you take U all ones(self.kernel_size[0],kernel_size[1], num_channels)\n",
    "        # its norm will sqrt(wxhxc)\n",
    "        print(\"Vars: \",self.input_channels,self.kernel_size[0],self.kernel_size[1])\n",
    "        masks *= K.sqrt(K.constant(self.input_channels*self.kernel_size[0]*self.kernel_size[1]))\n",
    "        \n",
    "        #masks *= (gain*np.sqrt(self.kernel_size[0]*self.kernel_size[1]))\n",
    "        #ums = sums * sums\n",
    "        #print(\"sums shape: \", sums.shape)\n",
    "        \n",
    "        # Sum normalisation\n",
    "        \n",
    "        #masks = masks * (gain/K.sqrt(sums))\n",
    "        #masks = masks * (gain/sums)\n",
    "        #print(\"masks shape\", masks.shape)\n",
    "        #print(\"masks mask\", K.mean(masks))\n",
    "        return masks\n",
    "\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_shape = K.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        if self.data_format == 'channels_first':\n",
    "          h_axis, w_axis = 2, 3\n",
    "          c_axis= 1\n",
    "          \n",
    "        else:\n",
    "            h_axis, w_axis = 1, 2\n",
    "            c_axis=3\n",
    "            \n",
    "        ##BTEK \n",
    "        in_channels =input_shape[c_axis]\n",
    "        \n",
    "\n",
    "\n",
    "        ##BTEK \n",
    "        print(\"Calling self.U:\")\n",
    "        kernel = self.U()\n",
    "        print(\"kernel shape in output:\",kernel.shape)\n",
    "        if self.input_channels>1:\n",
    "            kernel = K.repeat_elements(kernel, self.input_channels, axis=2)\n",
    "            print(\"kernel reshaped :\",kernel.shape)\n",
    "        print(\"inputs shape\",inputs.shape)\n",
    "        #print(K.eval(kernel))\n",
    "        # multiply with weights\n",
    "        kernel = kernel*self.W\n",
    "        \n",
    "        #---------------------------------------------------------------------\n",
    "        print(\"Trainable weights\", self._trainable_weights)\n",
    "        outputs = K.conv2d(\n",
    "                inputs,\n",
    "                kernel,\n",
    "                strides=self.strides,\n",
    "                padding=self.padding,\n",
    "                data_format=self.data_format,\n",
    "                dilation_rate=self.dilation_rate)\n",
    "        \n",
    "        print(outputs.shape)\n",
    "\n",
    "        if self.use_bias:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "        \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[1:-1]\n",
    "        elif self.data_format == 'channels_first':\n",
    "            space = input_shape[2:]\n",
    "        new_space = []\n",
    "        for i in range(len(space)):\n",
    "            new_dim = conv_utils.conv_output_length(\n",
    "                space[i],\n",
    "                self.kernel_size[i],\n",
    "                padding=self.padding,\n",
    "                stride=self.strides[i],\n",
    "                dilation=self.dilation_rate[i])\n",
    "            new_space.append(new_dim)\n",
    "        if self.data_format == 'channels_last':\n",
    "            return (input_shape[0],) + tuple(new_space) + (self.nfilters,)\n",
    "        elif self.data_format == 'channels_first':\n",
    "            return (input_shape[0], self.filters) + tuple(new_space)\n",
    "        #return tuple(output_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "#test\n",
    "def test():\n",
    "    import tensorflow as tf\n",
    "    #from gausslayer import GaussScaler\n",
    "    import numpy as np\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    from keras.losses import mse\n",
    "    import keras\n",
    "    from keras.datasets import mnist,fashion_mnist, cifar10\n",
    "    from keras.models import Sequential, Model\n",
    "    from keras.layers import Input, Dense, Dropout, Flatten\n",
    "    from skimage import filters\n",
    "    \n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    inputimg = x_train[0]/255\n",
    "    sh = (inputimg.shape[0],inputimg.shape[1],1)\n",
    "    outputimages = np.zeros(shape=[inputimg.shape[0],inputimg.shape[1],3],dtype='float32')\n",
    "    outputimages[:,:,0] = filters.gaussian(inputimg,sigma=1)\n",
    "    outputimages[:,:,1] = filters.sobel_h(inputimg)\n",
    "    outputimages[:,:,2] = filters.sobel_v(filters.gaussian(inputimg,sigma=0.5))\n",
    "    \n",
    "    y = y_train[0]\n",
    "    \n",
    "    node_in = Input(shape=sh, name='inputlayer')\n",
    "    node_acnn = Conv2DAdaptive(rank=2,nfilters=3,kernel_size=(7,7), \n",
    "                             data_format='channels_last',\n",
    "                             padding='same',name='acnn',activation='tanh',\n",
    "                             init_sigma=0.1, trainsigmas=True, \n",
    "                             trainWeights=True)(node_in)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    model = Model(inputs=node_in, outputs=[node_acnn])\n",
    "    model.reset_states()\n",
    "   # model.summary()\n",
    "\n",
    "    \n",
    "    sgd = keras.optimizers.SGD(lr=3.0, decay=0.000,momentum=0.0, nesterov=False)\n",
    "    model.compile(loss=mse, optimizer=sgd, metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    \n",
    "    inputimg2 = np.expand_dims(np.expand_dims(inputimg,axis=0), axis=3)\n",
    "    outputimages2 = np.expand_dims(outputimages,axis=0)\n",
    "    \n",
    "    model.fit(inputimg2, outputimages2,\n",
    "              batch_size=1,\n",
    "              epochs=50,\n",
    "              verbose=1)\n",
    "\n",
    "    \n",
    "    acnn_layer = model.get_layer('acnn')    \n",
    "    all_params=acnn_layer.weights\n",
    "    print(\"All params:\",all_params)\n",
    "    acnn_params = acnn_layer.get_weights()\n",
    "    for i,v in enumerate(all_params):\n",
    "        print(v, \":\", acnn_params[i],\"\\n\")\n",
    "    #out = acnn_layer.get_output_at(0)\n",
    "#\n",
    "#    with tf.Session() as sess:\n",
    "#        sess.run(tf.global_variables_initializer())\n",
    "#        outval = sess.run(out, feed_dict={inputs:inputimg2})\n",
    "#        acnn_layer_var = acnn_layer.get_weights()\n",
    "    \n",
    "    \n",
    "    pred_images = model.predict(inputimg2,  verbose=1)\n",
    "    print(\"Prediction shape\",pred_images.shape)\n",
    "    plt = True\n",
    "    if plt:\n",
    "        print(\"Plotting kernels before...\")\n",
    "        import matplotlib.pyplot as plt\n",
    "        num_images=min(pred_images.shape[3],12)\n",
    "        fig=plt.figure(figsize=(10,5))\n",
    "        plt.subplot(3, num_images, 2)\n",
    "        plt.imshow(np.squeeze(inputimg2[0,:,:,0]))\n",
    "        for i in range(num_images):\n",
    "            plt.subplot(3, num_images, i+4)\n",
    "            plt.imshow(np.squeeze(outputimages2[0,:,:,i]))\n",
    "            print(\"Max-in:\",i,\" \",np.max(np.squeeze(outputimages2[0,:,:,i])))\n",
    "        \n",
    "        for i in range(num_images):\n",
    "            plt.subplot(3, num_images, i+7)\n",
    "            plt.imshow(np.squeeze(pred_images[0,:,:,i]))\n",
    "            print(\"MAx:\",\"pred\",i,np.max(np.squeeze(pred_images[0,:,:,i])))\n",
    "        #fig.colorbar(im, ax=ax1)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    print( model.get_layer('acnn').output )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1915
    },
    "colab_type": "code",
    "id": "atu9imf6gQhl",
    "outputId": "fc2b7269-6ec8-455b-c806-4c526e5346b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               200832    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 230,698\n",
      "Trainable params: 230,442\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "<lr_multiplier.LearningRateMultiplier object at 0x7f314812b470>\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.3422 - acc: 0.8922 - val_loss: 0.0797 - val_acc: 0.9752\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.1081 - acc: 0.9676 - val_loss: 0.0468 - val_acc: 0.9843\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0817 - acc: 0.9752 - val_loss: 0.0465 - val_acc: 0.9850\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0679 - acc: 0.9786 - val_loss: 0.0325 - val_acc: 0.9890\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0589 - acc: 0.9825 - val_loss: 0.0329 - val_acc: 0.9887\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0537 - acc: 0.9833 - val_loss: 0.0321 - val_acc: 0.9890\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0498 - acc: 0.9852 - val_loss: 0.0372 - val_acc: 0.9874\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0465 - acc: 0.9856 - val_loss: 0.0268 - val_acc: 0.9909\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0433 - acc: 0.9869 - val_loss: 0.0245 - val_acc: 0.9920\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0395 - acc: 0.9880 - val_loss: 0.0230 - val_acc: 0.9927\n",
      "Test loss: 0.02296297775376006\n",
      "Test accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun 21 17:27:34 2019\n",
    "\n",
    "@author: btek\n",
    "\"\"\"\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist,cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization,Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "#dset='cifar10'#mnist\n",
    "dset='mnist'\n",
    "batch_size = 200\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "test_acnn=False\n",
    "\n",
    "if dset=='mnist':\n",
    "    # input image dimensions\n",
    "    img_rows, img_cols = 28, 28  \n",
    "    # the data, split between train and test sets\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    n_channels=1\n",
    "\n",
    "elif dset=='cifar10':    \n",
    "    img_rows, img_cols = 32,32\n",
    "    n_channels=3\n",
    "    \n",
    "    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], n_channels, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], n_channels, img_rows, img_cols)\n",
    "    input_shape = (n_channels, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, n_channels)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, n_channels)\n",
    "    input_shape = (img_rows, img_cols, n_channels)\n",
    "        \n",
    "\n",
    "    \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                   activation='linear',padding='same',\n",
    "          input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(32, (3, 3), activation='linear',padding='same'))\n",
    "#odel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "#odel.add(Dense(128, activation='relu'))\n",
    "\n",
    "#odel.add(Dropout(0.25))\n",
    "\n",
    "  #=============================================================================\n",
    "if test_acnn:\n",
    "    model.add(Conv2DAdaptive(rank=2,nfilters=32,kernel_size=(5,5), \n",
    "                         data_format='channels_last',strides=1,\n",
    "                         padding='same',name='acnn-1', activation='linear'))\n",
    "else:\n",
    "    model.add(Conv2D(32, (3, 3), activation='linear',padding='same'))\n",
    "    \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "if test_acnn:\n",
    "    model.add(Conv2DAdaptive(rank=2,nfilters=32,kernel_size=(5,5), \n",
    "                       data_format='channels_last',strides=1,\n",
    "                       padding='same',name='acnn-2', activation='linear'))\n",
    "else:\n",
    "    model.add(Conv2D(32, (3, 3), activation='linear',padding='same'))\n",
    "  \n",
    "      \n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "  \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "   \n",
    "#=============================================================================\n",
    "    \n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "from lr_multiplier import LearningRateMultiplier\n",
    "\n",
    "multipliers = {'acnn-1': 1.0,'acnn-2': 1.0}\n",
    "opt = LearningRateMultiplier(SGD, lr_multipliers=multipliers, \n",
    "                             lr=0.01, momentum=0.9,decay=1e-8)\n",
    "print(opt)\n",
    "#opt = SGD(lr=0.01,momentum=0.5)\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "plt = True\n",
    "if plt and test_acnn:\n",
    "    print(\"Plotting kernels before...\")\n",
    "    import matplotlib.pyplot as plt\n",
    "    acnn_layer = model.get_layer('acnn-1')\n",
    "    ws = acnn_layer.get_weights()\n",
    "    #print(\"Sigmas before\",ws[0][1])\n",
    "    u_func = K.function(inputs=[model.input], outputs=[acnn_layer.U()])\n",
    "    output_func = K.function(inputs=[model.input], outputs=[acnn_layer.output])\n",
    "\n",
    "    U_val=u_func([np.expand_dims(x_test[0], axis=0)])\n",
    "    \n",
    "    print(\"U shape\", U_val[0].shape)\n",
    "    print(\"U max:\", np.max(U_val[0][:,:,:,:]))\n",
    "    num_filt=min(U_val[0].shape[3],12)\n",
    "    fig=plt.figure(figsize=(10,5))\n",
    "    for i in range(num_filt):\n",
    "        ax1=plt.subplot(1, num_filt, i+1)\n",
    "        im = ax1.imshow(np.squeeze(U_val[0][:,:,0,i]))\n",
    "    fig.colorbar(im, ax=ax1)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "if plt and test_acnn:\n",
    "    print(\"Plotting kernels after ...\")\n",
    "    \n",
    "    print(\"U max:\", np.max(U_val[0][:,:,:,:]))\n",
    "    import matplotlib.pyplot as plt\n",
    "    ws = acnn_layer.get_weights()\n",
    "    #print(\"Sigmas after\",ws[0][1])\n",
    "    U_val=u_func([np.expand_dims(x_test[2], axis=0)])\n",
    "    \n",
    "    print(\"U shape\", U_val[0].shape)\n",
    "    num_filt=min(U_val[0].shape[3],12)\n",
    "    fig=plt.figure(figsize=(16,5))\n",
    "    for i in range(num_filt):\n",
    "        ax=plt.subplot(1, num_filt, i+1)\n",
    "        im = ax.imshow(np.squeeze(U_val[0][:,:,0,i]))\n",
    "    #fig.colorbar(im, ax=ax1)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(\"outputs  ...\")\n",
    "    \n",
    "    n=5\n",
    "    \n",
    "    out_val=output_func([np.expand_dims(x_test[5], axis=0)])\n",
    "    print(\"Outputs shape\", out_val[0].shape)\n",
    "    num_filt=min(out_val[0].shape[3],12)\n",
    "    fig=plt.figure(figsize=(16,10))\n",
    "    ax=plt.subplot(1, num_filt+1, 1)\n",
    "    im = ax.imshow(np.squeeze(x_test[5]))\n",
    "    print(y_test[5])\n",
    "    print(\"input mean,var,max\",np.mean(x_test[n]),np.var(x_test[n]),np.max(x_test[n]))\n",
    "    for i in range(num_filt):\n",
    "        ax=plt.subplot(1, num_filt+1, i+2)\n",
    "        out_im = out_val[0][0,:,:,i]\n",
    "        im = ax.imshow(np.squeeze(out_im))\n",
    "        print(\"ouput mean,var,max\",np.mean(out_im),\n",
    "                                       np.var(out_im),\n",
    "                                       np.max(out_im))\n",
    "        #plt.colorbar(im,ax=ax)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kY334rMlgTnT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Cas-keras",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
